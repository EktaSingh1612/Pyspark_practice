{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7270f818-d928-48ad-8c3c-8c31f5780765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/29 14:29:07 WARN Utils: Your hostname, EKTAs-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.100.4 instead (on interface en0)\n",
      "22/09/29 14:29:07 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/29 14:29:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/09/29 14:29:08 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/09/29 14:29:08 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Missing').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b7686b6-3c97-4bc7-86e1-f92d47f9ab48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------+\n",
      "|    Name| Age|Experience|Salary|\n",
      "+--------+----+----------+------+\n",
      "|   Virat|  34|        10| 60000|\n",
      "|   Rohit|  35|        13| 54000|\n",
      "|  Pandya|  29|         5| 30000|\n",
      "|   Panth|  25|         2| 20000|\n",
      "|   Dhoni|  40|        19| 51000|\n",
      "|   Rahul|  31|         6| 23000|\n",
      "| Shubham|null|      null| 17000|\n",
      "|Ravindra|  23|        10| 87000|\n",
      "|    null|  39|      null|  null|\n",
      "+--------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.read.csv('Cricket.csv',header=True, inferSchema=False)\n",
    "spark.read.csv('Cricket.csv',header=True, inferSchema=True).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0c80ac-627f-4593-85e9-d059bd804b18",
   "metadata": {},
   "source": [
    "## Drop the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b60fe9f9-3403-4eea-bcc6-560c39d06b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+------+\n",
      "| Age|Experience|Salary|\n",
      "+----+----------+------+\n",
      "|  34|        10| 60000|\n",
      "|  35|        13| 54000|\n",
      "|  29|         5| 30000|\n",
      "|  25|         2| 20000|\n",
      "|  40|        19| 51000|\n",
      "|  31|         6| 23000|\n",
      "|null|      null| 17000|\n",
      "|  23|        10| 87000|\n",
      "|  39|      null|  null|\n",
      "+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.drop('Name').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4529a680-0e72-43fe-aefe-34cb5bd1c39b",
   "metadata": {},
   "source": [
    "# Handling null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5566aae5-cb9d-463e-b7b2-6a3b84ca06cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+------+\n",
      "|    Name|Age|Experience|Salary|\n",
      "+--------+---+----------+------+\n",
      "|   Virat| 34|        10| 60000|\n",
      "|   Rohit| 35|        13| 54000|\n",
      "|  Pandya| 29|         5| 30000|\n",
      "|   Panth| 25|         2| 20000|\n",
      "|   Dhoni| 40|        19| 51000|\n",
      "|   Rahul| 31|         6| 23000|\n",
      "|Ravindra| 23|        10| 87000|\n",
      "+--------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad414b3-e3d4-40b6-85e4-f26425835719",
   "metadata": {},
   "source": [
    "df.na.drop(how='any').show() # if any value in a row has null values (default)\n",
    "df.na.drop(how='all').show() # if all values in a row is null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de409ca0-fc1f-4c9b-b33b-22a50d9cc337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------+\n",
      "|    Name| Age|Experience|Salary|\n",
      "+--------+----+----------+------+\n",
      "|   Virat|  34|        10| 60000|\n",
      "|   Rohit|  35|        13| 54000|\n",
      "|  Pandya|  29|         5| 30000|\n",
      "|   Panth|  25|         2| 20000|\n",
      "|   Dhoni|  40|        19| 51000|\n",
      "|   Rahul|  31|         6| 23000|\n",
      "| Shubham|null|      null| 17000|\n",
      "|Ravindra|  23|        10| 87000|\n",
      "+--------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# threshold -> minimum these many values needs to be null in a row\n",
    "\n",
    "df.na.drop(how='any',thresh=2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4ab732c-fc1f-43bb-8a42-d2f702de178d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+------+\n",
      "|    Name|Age|Experience|Salary|\n",
      "+--------+---+----------+------+\n",
      "|   Virat| 34|        10| 60000|\n",
      "|   Rohit| 35|        13| 54000|\n",
      "|  Pandya| 29|         5| 30000|\n",
      "|   Panth| 25|         2| 20000|\n",
      "|   Dhoni| 40|        19| 51000|\n",
      "|   Rahul| 31|         6| 23000|\n",
      "|Ravindra| 23|        10| 87000|\n",
      "+--------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# subset = remove null value only from a specific column\n",
    "\n",
    "df.na.drop(how='any', subset=['Experience']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21010b01-0383-4f17-b33a-b61780619d67",
   "metadata": {},
   "source": [
    "## Filling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62e13bdf-4c1b-44cc-a34a-c4a0e9a50845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+-------------+-------------+\n",
      "|         Name|          Age|   Experience|       Salary|\n",
      "+-------------+-------------+-------------+-------------+\n",
      "|        Virat|           34|           10|        60000|\n",
      "|        Rohit|           35|           13|        54000|\n",
      "|       Pandya|           29|            5|        30000|\n",
      "|        Panth|           25|            2|        20000|\n",
      "|        Dhoni|           40|           19|        51000|\n",
      "|        Rahul|           31|            6|        23000|\n",
      "|      Shubham|Missing value|Missing value|        17000|\n",
      "|     Ravindra|           23|           10|        87000|\n",
      "|Missing value|           39|Missing value|Missing value|\n",
      "+-------------+-------------+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.fillna('Missing value').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2aa2a46-72c7-45aa-9781-88533cee7458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+-------------+------+\n",
      "|    Name| Age|   Experience|Salary|\n",
      "+--------+----+-------------+------+\n",
      "|   Virat|  34|           10| 60000|\n",
      "|   Rohit|  35|           13| 54000|\n",
      "|  Pandya|  29|            5| 30000|\n",
      "|   Panth|  25|            2| 20000|\n",
      "|   Dhoni|  40|           19| 51000|\n",
      "|   Rahul|  31|            6| 23000|\n",
      "| Shubham|null|Missing value| 17000|\n",
      "|Ravindra|  23|           10| 87000|\n",
      "|    null|  39|Missing value|  null|\n",
      "+--------+----+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.fillna('Missing value','Experience').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60a758b0-4a3b-4ff2-b8f8-d4c9ca829534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+-------------+------+\n",
      "|    Name|          Age|   Experience|Salary|\n",
      "+--------+-------------+-------------+------+\n",
      "|   Virat|           34|           10| 60000|\n",
      "|   Rohit|           35|           13| 54000|\n",
      "|  Pandya|           29|            5| 30000|\n",
      "|   Panth|           25|            2| 20000|\n",
      "|   Dhoni|           40|           19| 51000|\n",
      "|   Rahul|           31|            6| 23000|\n",
      "| Shubham|Missing value|Missing value| 17000|\n",
      "|Ravindra|           23|           10| 87000|\n",
      "|    null|           39|Missing value|  null|\n",
      "+--------+-------------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.fillna('Missing value',['Experience','Age']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0429236-784d-4e07-b8a1-c8541438f401",
   "metadata": {},
   "source": [
    "### To fill the missing values with either mean, median or mode, we will use Imputer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "966381e7-bf1c-4e39-aeaa-dbffb8c075e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(inputCols=['Age','Experience','Salary'],\n",
    "                 outputCols=['{}_imputed'.format(c) for c in ['Age','Experience','Salary']]).setStrategy('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fedd372a-1484-4b16-8645-fac6bec5f651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------+-----------+------------------+--------------+\n",
      "|    Name| Age|Experience|Salary|Age_imputed|Experience_imputed|Salary_imputed|\n",
      "+--------+----+----------+------+-----------+------------------+--------------+\n",
      "|   Virat|  34|        10| 60000|         34|                10|         60000|\n",
      "|   Rohit|  35|        13| 54000|         35|                13|         54000|\n",
      "|  Pandya|  29|         5| 30000|         29|                 5|         30000|\n",
      "|   Panth|  25|         2| 20000|         25|                 2|         20000|\n",
      "|   Dhoni|  40|        19| 51000|         40|                19|         51000|\n",
      "|   Rahul|  31|         6| 23000|         31|                 6|         23000|\n",
      "| Shubham|null|      null| 17000|         32|                 9|         17000|\n",
      "|Ravindra|  23|        10| 87000|         23|                10|         87000|\n",
      "|    null|  39|      null|  null|         39|                 9|         42750|\n",
      "+--------+----+----------+------+-----------+------------------+--------------+\n",
      "\n",
      "22/10/05 19:30:31 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 935019 ms exceeds timeout 120000 ms\n",
      "22/10/05 19:30:31 WARN SparkContext: Killing executors is not supported by current scheduler.\n"
     ]
    }
   ],
   "source": [
    "# Add imputation cols to df\n",
    "\n",
    "df=spark.read.csv('Cricket.csv',header=True, inferSchema=True)\n",
    "\n",
    "imputer.fit(df).transform(df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56289515-e77a-4d3b-b2c7-b868149982e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
